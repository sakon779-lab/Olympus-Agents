import sys
import json
import logging
import re
import os
import ast
import uuid
from datetime import datetime
from typing import Dict, Any, List
import core.network_fix

# âœ… Core Configuration & LLM
from core.config import settings
from core.llm_client import query_qwen

# âœ… Core Tools
from core.tools.jira_ops import get_jira_issue
from core.tools.file_ops import read_file, list_files
from core.tools.git_ops import git_setup_workspace, git_commit, git_push, create_pr, git_pull

# Logging Setup
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - [Athena] %(message)s')
logger = logging.getLogger("Athena")


# ==============================================================================
# ðŸ“ DUAL LOGGER CLASS
# ==============================================================================
class DualLogger:
    """Writes output to BOTH the terminal (stdout) and a log file simultaneously."""

    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log_file = open(filename, "a", encoding="utf-8")

    def write(self, message):
        self.terminal.write(message)
        self.log_file.write(message)
        self.log_file.flush()

    def flush(self):
        self.terminal.flush()
        self.log_file.flush()

    def close(self):
        self.log_file.close()


# ==============================================================================
# ðŸ› ï¸ AGENT SPECIFIC TOOLS
# ==============================================================================

def save_test_design(filename: str, content: str) -> str:
    """Saves Test Scenarios (CSV) to the QA Repo."""
    try:
        if not filename.endswith('.csv'): filename += ".csv"

        # âœ… FIX 1: à¹ƒà¸Šà¹‰ path à¹€à¸”à¸´à¸¡à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸ (settings.TEST_DESIGN_DIR)
        target_dir = settings.TEST_DESIGN_DIR
        full_path = os.path.join(target_dir, filename)

        # à¸ªà¸£à¹‰à¸²à¸‡ folder à¸«à¸²à¸à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ
        os.makedirs(os.path.dirname(full_path), exist_ok=True)

        # Clean logic: Remove markdown code blocks
        clean_content = content.replace("```csv", "").replace("```", "").strip()

        # Remove empty lines
        lines = [line for line in clean_content.splitlines() if line.strip()]
        final_content = "\n".join(lines)

        with open(full_path, "w", encoding="utf-8", newline='') as f:
            f.write(final_content)

        return f"âœ… Test Design Saved: {full_path}"
    except Exception as e:
        return f"âŒ Error Saving CSV: {e}"


# ==============================================================================
# ðŸ§© TOOL REGISTRY & SCHEMAS (Added)
# ==============================================================================

TOOLS = {
    "get_jira_issue": get_jira_issue,
    "list_files": list_files,
    "read_file": read_file,
    "git_setup_workspace": git_setup_workspace,
    "git_commit": git_commit,
    "git_push": git_push,
    "create_pr": create_pr,
    "git_pull": git_pull,
    "save_test_design": save_test_design
}

# âœ… FIX 2: à¹€à¸žà¸´à¹ˆà¸¡ Schema Verification à¹€à¸«à¸¡à¸·à¸­à¸™ Hephaestus
TOOL_SCHEMAS = {
    "get_jira_issue": {
        "required": ["issue_key"],
        "description": "Fetches details of a JIRA issue."
    },
    "git_setup_workspace": {
        "required": ["issue_key"],
        "optional": ["base_branch", "agent_name", "job_id"],  # Injectable args
        "description": "Clones repo and checks out branch."
    },
    "save_test_design": {
        "required": ["filename", "content"],
        "description": "Saves CSV content to the test design folder."
    },
    "git_commit": {
        "required": ["message"],
        "description": "Commits changes."
    },
    "git_push": {
        "required": [],
        "optional": ["branch_name"],
        "description": "Pushes changes to remote."
    },
    "git_pull": {
        "required": [],
        "optional": ["branch_name"],
        "description": "Pulls latest changes."
    },
    "create_pr": {
        "required": ["title"],
        "optional": ["body", "base_branch", "head_branch"],
        "description": "Creates a GitHub Pull Request."
    },
    "list_files": {
        "required": [],
        "optional": ["directory"],
        "description": "Lists files."
    },
    "read_file": {
        "required": ["file_path"],  # à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­ argument à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¸à¸±à¸š function à¸ˆà¸£à¸´à¸‡
        "description": "Reads file content."
    },
    "task_complete": {
        "required": [],
        "optional": ["summary"],
        "description": "Marks task as finished."
    }
}


def execute_tool_dynamic(tool_name: str, args: Dict[str, Any]) -> Dict[str, Any]:
    if tool_name not in TOOLS:
        return {"success": False, "output": f"Error: Unknown tool '{tool_name}'"}

    # âœ… Schema Validation Logic
    if tool_name in TOOL_SCHEMAS:
        schema = TOOL_SCHEMAS[tool_name]
        valid_keys = set(schema.get("required", []))
        if "optional" in schema:
            valid_keys.update(schema["optional"])

        # Check unknown args
        unknown_args = set(args.keys()) - valid_keys
        if unknown_args:
            return {
                "success": False,
                "output": f"[ERROR] Invalid arguments: {list(unknown_args)}. Allowed: {list(valid_keys)}"
            }

        # Check missing args
        missing = [k for k in schema.get("required", []) if k not in args]
        if missing:
            return {"success": False, "output": f"[ERROR] Missing required arguments: {missing}"}

    try:
        func = TOOLS[tool_name]
        raw_result = str(func(**args))
        is_success = "âœ…" in raw_result or "SUCCESS" in raw_result.upper()
        clean_output = raw_result.replace("âœ…", "[SUCCESS]").replace("âŒ", "[ERROR]")
        return {"success": is_success, "output": clean_output}
    except Exception as e:
        return {"success": False, "output": f"Error executing {tool_name}: {str(e)}"}


# ==============================================================================
# ðŸ§  SYSTEM PROMPT
# ==============================================================================
CSV_BLOCK_START = "```" + "csv"
CSV_BLOCK_END = "```"

SYSTEM_PROMPT = f"""
You are "Athena", the Senior QA Lead.
Your goal is to design Data-Driven Test Cases (CSV) based on Jira Requirements.

*** ðŸ›‘ CORE PHILOSOPHY (DO NOT IGNORE) ***
1. **SOURCE OF TRUTH**: The Jira Ticket (Markdown) is the ONLY truth.
   - If Jira says "Return 400", you MUST expect 400. (Do NOT assume 404).
   - **Suppress your AI bias**: Do not use "Standard HTTP behavior" if the Requirement says otherwise.

2. **STATUS CODE EXTRACTION**:
   - Before designing, SCAN the requirement for HTTP Status Codes (200, 400, 404, 500).
   - Use these EXACT codes in your `ExpectedResult`.

*** ðŸ› ï¸ TOOL SIGNATURES (STRICT) ***
You MUST use these exact argument names:
1. `get_jira_issue(issue_key)`
2. `git_setup_workspace(issue_key)`
3. `save_test_design(filename, content)`
4. `git_commit(message)`
5. `git_push(branch_name)`
6. `create_pr(title, body)`
7. `git_pull(branch_name)` (Use if push fails)

*** âš¡ CONTENT DELIVERY RULE (CRITICAL) ***
When calling `save_test_design`, do NOT put the CSV inside the JSON.
Instead, output a Markdown Code Block tagged with `csv` AFTER the JSON.

**CORRECT FORMAT:**
{{ "action": "save_test_design", "args": {{ "filename": "SCRUM-26.csv" }} }}

{CSV_BLOCK_START}
CaseID, TestType, Description, PreRequisites, Steps, ExpectedResult
TC-001, Positive, Verify API, Mock: None, Call GET /api, 200 OK
{CSV_BLOCK_END}

*** ðŸ›¡ï¸ ERROR HANDLING STRATEGIES (GIT) ***
- **IF `git_push` FAILS** (rejected/non-fast-forward):
  1. STOP! Do NOT create PR yet.
  2. Call `git_pull(branch_name)` to sync changes.
  3. Call `git_push(branch_name)` AGAIN to retry.
  4. Only then, proceed to `create_pr`.

*** âš¡ WORKFLOW (STRICT ORDER) ***
1. `get_jira_issue` -> Wait for result.
2. `git_setup_workspace` -> Wait for result.
3. `save_test_design` (MUST include CSV block) -> Wait for result.
4. `git_commit` -> Wait for result.
5. `git_push` -> Wait for result.
6. `create_pr` -> Wait for result.
7. `task_complete`.

RESPONSE FORMAT (JSON ONLY + MARKDOWN BLOCK):
{{ "action": "tool_name", "args": {{ ... }} }}
"""


# ==============================================================================
# ðŸ§© HELPER: ROBUST PARSERS
# ==============================================================================

def sanitize_json_input(raw_text):
    """Cleans up the LLM response to ensure valid JSON."""
    clean_text = re.sub(r'^```json\s*', '', raw_text, flags=re.MULTILINE)
    clean_text = re.sub(r'^```\s*', '', clean_text, flags=re.MULTILINE)
    clean_text = re.sub(r'```$', '', clean_text, flags=re.MULTILINE)

    def fix_triple_quotes(match):
        content = match.group(1).replace('\\', '\\\\').replace('"', '\\"').replace('\n', '\\n')
        return f'"{content}"'

    clean_text = re.sub(r'"""(.*?)"""', fix_triple_quotes, clean_text, flags=re.DOTALL)

    clean_text = clean_text.strip()

    # Python Dict -> JSON Auto-Fix
    try:
        py_compatible_text = clean_text.replace("true", "True").replace("false", "False").replace("null", "None")
        parsed = ast.literal_eval(py_compatible_text)
        if isinstance(parsed, (dict, list)):
            return json.dumps(parsed)
    except Exception:
        pass

    return clean_text


def extract_csv_block(text: str) -> str:
    """Extract CSV content precisely."""
    csv_matches = re.findall(r"```csv\n(.*?)```", text, re.DOTALL)
    if csv_matches:
        return csv_matches[-1].strip()

    matches = re.findall(r"```(?:\w+)?\n(.*?)```", text, re.DOTALL)
    for content in reversed(matches):
        cleaned = content.strip()
        if not (cleaned.startswith("{") and "action" in cleaned):
            return cleaned
    return ""


def _extract_all_jsons(text: str) -> List[Dict[str, Any]]:
    """Robust JSON extraction including Python Dict fallback."""
    results = []
    decoder = json.JSONDecoder()
    pos = 0
    while pos < len(text):
        try:
            search = re.search(r"\{", text[pos:])
            if not search: break
            start_index = pos + search.start()
            obj, end_index = decoder.raw_decode(text, idx=start_index)
            if isinstance(obj, dict) and "action" in obj:
                results.append(obj)
            pos = end_index
        except:
            pos += 1

    if not results:
        try:
            matches = re.findall(r"(\{.*?\})", text, re.DOTALL)
            for match in matches:
                try:
                    clean = match.replace("true", "True").replace("false", "False").replace("null", "None")
                    obj = ast.literal_eval(clean)
                    if isinstance(obj, dict) and "action" in obj: results.append(obj)
                except:
                    continue
        except:
            pass
    return results


# ==============================================================================
# ðŸš€ MAIN LOOP (Athena Version)
# ==============================================================================
def run_athena_task(task: str, job_id: str = None, max_steps: int = 25):
    if settings.CURRENT_AGENT_NAME != "Athena":
        settings.CURRENT_AGENT_NAME = "Athena"

    if not job_id:
        job_id = f"qa_{uuid.uuid4().hex[:8]}"

    # --- Path Setup ---
    current_script_path = os.path.abspath(__file__)
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_script_path)))
    logs_dir = os.path.join(project_root, "logs", "athena")
    os.makedirs(logs_dir, exist_ok=True)
    log_filename = os.path.join(logs_dir, f"job_{job_id}.log")

    # Setup Dual Logger
    original_stdout = sys.stdout
    dual_logger = DualLogger(log_filename)
    sys.stdout = dual_logger

    final_result = None  # à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸ªà¹ˆà¸‡à¸„à¸·à¸™ Worker

    try:
        print(f"\n==================================================")
        print(f"ðŸ¦‰ Launching Athena (Test Architect)...")
        print(f"â–¶ï¸ [Worker] Starting Job {job_id}")
        print(f"ðŸ“… Time: {datetime.now()}")
        print(f"ðŸ“‹ Task: {task}")
        print(f"ðŸ“ Log File: {os.path.abspath(log_filename)}")
        print(f"==================================================\n")

        history = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": task}
        ]

        for step in range(max_steps):
            print(f"\nðŸ”„ Thinking (Step {step + 1})...")
            try:
                response = query_qwen(history)
                if isinstance(response, dict):
                    content = response.get('message', {}).get('content', '') or response.get('content', '')
                else:
                    content = str(response)
            except Exception as e:
                print(f"âŒ Error querying LLM: {e}")
                return "Error: LLM Query Failed"

            print(f"ðŸ¤– Athena: {content[:100].replace(os.linesep, ' ')}...")

            # Clean and Extract
            content_cleaned = sanitize_json_input(content)
            tool_calls = _extract_all_jsons(content_cleaned)

            if not tool_calls:
                if "complete" in content.lower() or "completed" in content.lower():
                    print("â„¹ï¸ Athena likely finished thinking without explicit tool call.")
                history.append({"role": "assistant", "content": content})
                continue

            step_outputs = []
            task_finished = False

            # Execute Tools
            for tool_call in tool_calls:
                action = tool_call.get("action")
                args = tool_call.get("args", {})

                # âœ… à¹à¸à¹‰à¹„à¸‚à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸—à¸³à¹ƒà¸«à¹‰ Result à¹€à¸›à¹‡à¸™ None
                if action == "task_complete":
                    task_finished = True
                    # à¸–à¹‰à¸² AI à¸ªà¹ˆà¸‡ args à¸§à¹ˆà¸²à¸‡à¸¡à¸² à¹ƒà¸«à¹‰à¸žà¸¢à¸²à¸¢à¸²à¸¡à¸”à¸¶à¸‡ content à¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²à¸¡à¸²à¹€à¸›à¹‡à¸™ summary
                    result_summary = args.get("summary") or args.get("result")
                    if not result_summary:
                        result_summary = "Task completed successfully (No explicit summary provided)."

                    final_result = result_summary
                    step_outputs.append(f"Task Completed: {result_summary}")
                    break

                # --- ðŸ’‰ MIDDLEWARE INJECTION (System Overrides) ---
                if action == "git_setup_workspace":
                    args["job_id"] = job_id
                    current_agent = getattr(settings, "CURRENT_AGENT_NAME", "Athena")
                    args["agent_name"] = current_agent
                    print(f"ðŸ’‰ System Injected: agent_name='{current_agent}', job_id='{job_id}'")

                # âš¡ Content Detachment Logic (CSV Stitching)
                if action == "save_test_design":
                    if "content" not in args or len(args.get("content", "")) < 10:
                        csv_content = extract_csv_block(content)
                        if csv_content:
                            args["content"] = csv_content
                            print("ðŸ“ Extracted CSV from Markdown block.")
                        else:
                            print("âš ï¸ Warning: No CSV content found in markdown.")
                            step_outputs.append("Error: CSV content missing from Markdown block.")
                            continue

                print(f"ðŸ”§ Executing: {action}")

                # Execute with Schema Validation
                res_data = execute_tool_dynamic(action, args)
                result_for_ai = res_data["output"]

                print(f"ðŸ“„ Result: {str(result_for_ai)[:300]}...")
                step_outputs.append(f"Tool Output ({action}): {result_for_ai}")

                # Athena usually does 1 thing at a time
                break

            if task_finished:
                print(f"\nâœ… TASK COMPLETE.")  # ðŸŸ¢ à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸‚à¸­
                return final_result  # ðŸŸ¢ à¸„à¸·à¸™à¸„à¹ˆà¸²à¸­à¸­à¸à¹„à¸›à¹ƒà¸«à¹‰ Worker à¹€à¸à¹‡à¸šà¸¥à¸‡ JOBS

            history.append({"role": "assistant", "content": content})
            history.append({"role": "user", "content": "\n".join(step_outputs)})

        print("âŒ FAILED: Max steps reached.")
        return "Failed: Maximum steps reached."

    finally:
        if 'original_stdout' in locals():
            sys.stdout = original_stdout
        if 'dual_logger' in locals():
            dual_logger.close()


if __name__ == "__main__":
    if len(sys.argv) > 1:
        run_athena_task(sys.argv[1])
    else:
        run_athena_task("Design QA for SCRUM-29")
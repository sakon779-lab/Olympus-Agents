import json
import logging
import re
import os
import sys
import ast  # ‚úÖ [FIX 1] ‡πÄ‡∏û‡∏¥‡πà‡∏° import ast
from typing import Dict, Any, List


# ‚úÖ Core Modules
from core.llm_client import query_qwen, get_langchain_llm
from core.config import settings

# ‚úÖ Core Tools (Knowledge Only)
from core.tools.jira_ops import get_jira_issue
from core.tools.knowledge_ops import save_knowledge, get_knowledge_from_sql

# ‚úÖ Knowledge Base Integration (Vector Store)
from knowledge_base.vector_store import search_vector_db

# ‚úÖ LangChain & SQL Agent (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Database ‡∏à‡∏£‡∏¥‡∏á)
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits import create_sql_agent

# Logging Setup
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - [Apollo] %(message)s')
logger = logging.getLogger("ApolloAgent")
os.environ["ANONYMIZED_TELEMETRY"] = "False"

# ==============================================================================
# üîå DATABASE CONNECTION (PostgreSQL - Application DB)
# ==============================================================================
try:
    # ‡πÉ‡∏ä‡πâ settings.DATABASE_URI ‡∏à‡∏≤‡∏Å config.py
    app_db = SQLDatabase.from_uri(settings.DATABASE_URI, sample_rows_in_table_info=0)

    # ‡∏î‡∏∂‡∏á LLM ‡πÅ‡∏ö‡∏ö LangChain Object
    agent_llm = get_langchain_llm(temperature=0)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á SQL Agent Executor
    sql_agent_executor = create_sql_agent(
        llm=agent_llm,
        db=app_db,
        agent_type="zero-shot-react-description",
        # verbose=True, # üëà ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô True ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö run ‡∏ú‡πà‡∏≤‡∏ô console
        verbose=False,  # üëà ‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô False (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MCP)
        handle_parsing_errors=True  # <-- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô error
    )
    SQL_ANALYST_ACTIVE = True
    logger.info(f"‚úÖ SQL Analyst: Connected to DB at {settings.DB_HOST}")
except Exception as e:
    logger.error(f"‚ùå SQL Analyst: Connection Failed - {e}")
    SQL_ANALYST_ACTIVE = False

# ==============================================================================
# üõ†Ô∏è APOLLO SPECIFIC TOOLS
# ==============================================================================
def ask_database_analyst(question: str) -> str:
    """
    Expert on Data & Statistics.
    """
    if not SQL_ANALYST_ACTIVE:
        return "‚ùå Error: Cannot connect to the application database."

    logger.info(f"üìä Analyst querying: {question}")
    try:
        # ‚úÖ DYNAMIC PROMPT: ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á (Count)
        # ‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ Agent ‡πÉ‡∏ä‡πâ‡∏™‡∏°‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå
        forced_prompt = (
            f"Role: You are an Intelligent SQL Data Analyst.\n"
            f"Goal: Answer the user's question accurately using the PostgreSQL database.\n\n"

            f"üß† THINKING PROTOCOL (Must follow):\n"
            f"1. **Analyze Intent**: Does the user want to Count? List? Sum? or Check details?\n"
            f"2. **Identify Table**: Look for the most relevant table based on keywords (e.g., 'tickets'->jira_knowledge, 'people'->users).\n"
            f"3. **Inspect Data (Crucial)**: If the user asks to filter by text (e.g., status, role, type), NEVER guess the value.\n"
            f"   -> Action: Run `SELECT DISTINCT column FROM table LIMIT 10` first.\n"
            f"4. **Execute Final Query**: Once you know the exact values and table, execute the specific SQL that answers the question.\n\n"

            f"Question: {question}\n\n"
            # Chain of Thought Starter: ‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡∏¥‡∏î‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡∏Å‡∏™‡∏∑‡∏ö
            f"Let's think step by step. First, I need to identify which table contains the requested information.\n"
            f"Action:"
        )

        result = sql_agent_executor.invoke(forced_prompt)
        output = result.get('output', str(result))
        return f"üìä Database Analysis Result:\n{output}"
    except Exception as e:
        return f"‚ùå SQL Analyst Error: {e}"

def ask_guru(question: str) -> str:
    """
    Expert on Business Logic & Jira Tickets.
    Use this for: "What is SCRUM-26?", "Explain login logic", "How does X work?".
    NOT for: Counting or Statistics.
    """
    logger.info(f"üîé Guru received: {question}")

    # üéØ Layer 1: The Sniper (Exact Match via Regex)
    # ‡∏´‡∏≤‡∏ß‡πà‡∏≤‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏°‡∏µ‡∏£‡∏´‡∏±‡∏™ Ticket ‡πÑ‡∏´‡∏° (‡πÄ‡∏ä‡πà‡∏ô SCRUM-26, PAY-101)
    ticket_pattern = r"([A-Z]+-\d+)"
    matches = re.findall(ticket_pattern, question)

    if matches:
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ ID ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏£‡∏á‡πÜ ‡∏à‡∏≤‡∏Å SQL (Internal Knowledge DB)
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ô‡∏µ‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Å‡∏ß‡πà‡∏≤ Vector Search ‡∏°‡∏≤‡∏Å
        logger.info(f"üéØ Direct Lookup IDs: {matches}")
        results = []
        for ticket_key in matches:
            data = get_knowledge_from_sql(ticket_key)  # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ
            if data:
                results.append(f"üìÑ Ticket {ticket_key}:\n{data}")

        if results:
            return "\n---\n".join(results)

    # üìö Layer 2: The Librarian (Vector Search)
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ID ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Vector Search ‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢
    logger.info("üß† Fallback to Semantic Search...")
    try:
        results = search_vector_db(question, k=4)
        if not results or "no relevant info" in results.lower():
            return "‚ùå No info found in knowledge base."
        return f"üìö Relevant Docs found:\n{results}"
    except Exception as e:
        return f"‚ùå Search Error: {e}"

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ö‡∏ö One-Stop Service
def sync_ticket_to_knowledge_base(issue_key: str) -> str:
    """
    Orchestrate the sync process: Read Jira -> Extract Info using LLM -> Save to Vector DB
    """
    logger.info(f"üîÑ Syncing Ticket: {issue_key}")

    # 1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (One Shot)
    ticket_data = get_jira_issue(issue_key)

    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ Error ‡πÑ‡∏´‡∏°
    if not ticket_data.get("success"):
        return f"‚ùå Sync Failed: {ticket_data.get('error')}"

    # ‚úÖ ‡πÑ‡∏î‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏Ñ‡∏£‡∏ö ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏¢‡∏¥‡∏á‡∏£‡∏≠‡∏ö‡∏™‡∏≠‡∏á
    raw_content = ticket_data["ai_content"]  # ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI ‡∏≠‡πà‡∏≤‡∏ô
    real_status = ticket_data["status"]  # ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ Save ‡∏•‡∏á DB
    real_type = ticket_data["issue_type"]  # ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ Save ‡∏•‡∏á DB
    real_summary = ticket_data["summary"]  # ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ Save ‡∏•‡∏á DB

    # 2. ‡πÉ‡∏ä‡πâ‡∏™‡∏°‡∏≠‡∏á (Qwen) ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Structured Data (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡∏•‡∏á DB ‡∏™‡∏ß‡∏¢‡πÜ)
    # ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á Prompt ‡πÉ‡∏´‡πâ‡∏°‡∏±‡∏ô‡∏ñ‡∏≠‡∏î Business Logic ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
    extraction_prompt = [
        {"role": "system", "content": """
You are a Data Extractor. parsing Jira ticket content into structured JSON.
Extract the following fields strictly:
- summary: The title of the ticket.
- status: The current status (e.g., To Do, Done).
- business_logic: The core rules and requirements.
- technical_spec: API endpoints, database changes, or technical constraints.
- test_scenarios: Acceptance criteria or test cases mentioned.
- issue_type: (Story, Bug, Task).
STRICT RULES:
1. Use double quotes (") for keys and string values.
2. Escape inner quotes properly (e.g. "behavior": "Returns \\"Error\\" message").
3. Do NOT use single quotes (') for JSON strings.
4. Output JSON ONLY. No markdown, no explanations.
"""},
        {"role": "user", "content": f"Parse this ticket content:\n\n{raw_content}"}
    ]

    try:
        llm_response = query_qwen(extraction_prompt)

        # Handle Response Type
        if isinstance(llm_response, dict):
            content_text = llm_response.get('content', '') or llm_response.get('message', {}).get('content', '')
        else:
            content_text = str(llm_response)

        # üõ°Ô∏è Safety Clean: ‡∏•‡πâ‡∏≤‡∏á Markdown ‡∏≠‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏•‡∏µ‡πâ‡∏¢‡∏á (‡∏Å‡∏±‡∏ô‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß)
        content_text = content_text.strip()
        if content_text.startswith("```json"):
            content_text = content_text[7:]
        if content_text.endswith("```"):
            content_text = content_text[:-3]

        content_text = content_text.strip()

        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Dict
        data = json.loads(content_text)

        # üî• [HELPER] ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏õ‡∏•‡∏á Dict/List ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô String ‡πÉ‡∏´‡πâ DB ‡∏≠‡πà‡∏≤‡∏ô‡∏≠‡∏≠‡∏Å
        def safe_serialize(obj):
            if isinstance(obj, (dict, list)):
                # ensure_ascii=False ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢/Emoji ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô \uXXXX
                return json.dumps(obj, ensure_ascii=False, indent=2)
            return str(obj) if obj else "-"

        # 3. ‡∏ï‡∏≠‡∏ô Save ‡∏Å‡πá‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å
        result = save_knowledge(
            issue_key=issue_key,
            summary=real_summary,  # ‚úÖ ‡∏à‡∏≤‡∏Å API
            status=real_status,  # ‚úÖ ‡∏à‡∏≤‡∏Å API
            business_logic=safe_serialize(data.get("business_logic")),
            technical_spec=safe_serialize(data.get("technical_spec")),
            test_scenarios=safe_serialize(data.get("test_scenarios")),
            issue_type=real_type  # ‚úÖ ‡∏à‡∏≤‡∏Å API
        )

        return f"‚úÖ Synced {issue_key} successfully!\nDetails: {result}"

    except json.JSONDecodeError as je:
        logger.error(f"‚ùå JSON Error: {je} \nRaw Text: {content_text}")
        # Fallback: Save Raw Content
        # ‚úÖ ‡πÉ‡∏ä‡πâ real_summary, real_status, real_type ‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á ‡πÅ‡∏°‡πâ AI ‡∏à‡∏∞‡πÄ‡∏≠‡πã‡∏≠
        save_knowledge(
            issue_key=issue_key,
            summary=f"[AI Error] {real_summary}",  # ‡πÅ‡∏õ‡∏∞‡∏õ‡πâ‡∏≤‡∏¢‡∏ö‡∏≠‡∏Å‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏ß‡πà‡∏≤ AI ‡∏û‡∏±‡∏á ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ
            status=real_status,  # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á
            business_logic=f"‚ö†Ô∏è AI Parsing Failed. Raw Content:\n{raw_content[:2000]}",  # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏î‡∏¥‡∏ö‡πÑ‡∏ß‡πâ debug
            technical_spec="-",
            test_scenarios="-",
            issue_type=real_type  # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á
        )

        return f"‚ö†Ô∏è Synced {issue_key} (Metadata OK, but AI Analysis failed). Saved raw content."

    except Exception as e:
        logger.error(f"‚ùå General Error: {e}")
        return f"‚ùå Sync Failed: {e}"

# ==============================================================================
# üß© TOOLS REGISTRY
# ==============================================================================
TOOLS = {
    "ask_guru": ask_guru,             # ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ (Docs/Jira/Internal SQL)
    "ask_database_analyst": ask_database_analyst, # ‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á (External Postgres)
    "sync_ticket": sync_ticket_to_knowledge_base
}

def execute_tool_dynamic(tool_name: str, args: Dict[str, Any]) -> str:
    if tool_name not in TOOLS: return f"Error: Unknown tool '{tool_name}'"
    try:
        func = TOOLS[tool_name]
        return str(func(**args))
    except Exception as e:
        return f"Error executing {tool_name}: {e}"

# ==============================================================================
# üß† SYSTEM PROMPT
# ==============================================================================
SYSTEM_PROMPT = """
You are "Apollo", the Knowledge Guru & Data Analyst of Olympus.

*** üß† DECISION TREE (Follow Strictly) ***

1. **CASE: User asks for DEFINITION / LOGIC / CONTENT** üìñ
   - Examples: "What is SCRUM-26?", "Explain the login flow", "Show me the requirements".
   - ‚úÖ ACTION: Use `ask_guru(question)`.
   - (This tool handles both specific ticket IDs and general semantic search).

2. **CASE: User asks for NUMBERS / LISTS / AGGREGATION** üìä
   - Examples: "How many tickets?", "Count users", "List all tickets in To Do".
   - ‚úÖ ACTION: Use `ask_database_analyst(question)`.
   - (This tool runs SQL queries to get exact stats).

3. **CASE: User asks to MEMORIZE / SYNC** üì•
   - Examples: "Sync SCRUM-27", "Read this ticket".
   - ‚úÖ ACTION: `read_jira_ticket` -> `save_knowledge`.

*** ‚ö†Ô∏è RULES ***
- Do NOT guess. If you need stats, ask the analyst.
- If you need content, ask the guru.
- Output JSON format only.

*** ‚ö†Ô∏è CRITICAL RULES ***
1. **ATOMICITY**: One tool per turn. Wait for result.
2. **JSON FORMAT**: No comments. Strict JSON.
3. **PRIORITY**: Answer the question directly based on tool output.

*** üõ†Ô∏è TOOLS AVAILABLE ***
- sync_ticket(issue_key)  <-- üü¢ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
- ask_guru(question)
- ask_database_analyst(question)
- task_complete(summary)

RESPONSE FORMAT (JSON ONLY):
{ "action": "tool_name", "args": { ... } }
"""


# ==============================================================================
# üß© HELPER: PARSERS (Standardized)
# ==============================================================================
def extract_code_block(text: str) -> str:
    """Extract content from Markdown code blocks."""
    matches = re.findall(r"```\w*\n(.*?)```", text, re.DOTALL)
    if not matches: return ""
    for content in reversed(matches):
        cleaned = content.strip()
        if not ('"action":' in cleaned and '"args":' in cleaned):
            return cleaned
    return ""


def _extract_all_jsons(text: str) -> List[Dict[str, Any]]:
    """ robust JSON extractor handling multiple blocks and python dict strings """
    results = []
    decoder = json.JSONDecoder()
    pos = 0
    while pos < len(text):
        try:
            search = re.search(r"\{", text[pos:])
            if not search: break
            start_index = pos + search.start()
            obj, end_index = decoder.raw_decode(text, idx=start_index)
            if isinstance(obj, dict) and "action" in obj:
                results.append(obj)
            pos = end_index
        except:
            pos += 1

    if not results:
        # Fallback for Python dict strings
        try:
            matches = re.findall(r"(\{.*?\})", text, re.DOTALL)
            for match in matches:
                try:
                    clean = match.replace("true", "True").replace("false", "False").replace("null", "None")
                    obj = ast.literal_eval(clean)
                    if isinstance(obj, dict) and "action" in obj: results.append(obj)
                except:
                    continue
        except:
            pass
    return results


# ==============================================================================
# üöÄ MAIN LOOP
# ==============================================================================
def run_apollo_task(task: str, max_steps: int = 15):
    # Set Identity for Path Handling
    if settings.CURRENT_AGENT_NAME != "Apollo":
        settings.CURRENT_AGENT_NAME = "Apollo"

    print(f"üèõÔ∏è Launching Apollo (Knowledge Guru)...")
    print(f"üìã Question/Task: {task}")

    history = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": task}
    ]

    for step in range(max_steps):
        print(f"\nüîÑ Thinking (Step {step + 1})...")
        try:
            response = query_qwen(history)

            # Handle Response Type (Dict vs String)
            if isinstance(response, dict):
                content = response.get('message', {}).get('content', '') or response.get('content', '')
            else:
                content = str(response)

        except Exception as e:
            print(f"‚ùå Error querying LLM: {e}")
            return

        print(f"ü§ñ Apollo: {content[:100]}...")

        tool_calls = _extract_all_jsons(content)

        if not tool_calls:
            # Check for final answer or thought
            if "task_complete" not in content and "action" not in content:
                print(f"‚ÑπÔ∏è Apollo Answer: {content}")
                history.append({"role": "assistant", "content": content})
            else:
                history.append({"role": "assistant", "content": content})
            continue

        step_outputs = []
        task_finished = False

        for tool_call in tool_calls:
            action = tool_call.get("action")
            args = tool_call.get("args", {})

            if action == "task_complete":
                task_finished = True
                result = args.get("summary", "Done")
                step_outputs.append(f"Task Completed: {result}")
                break

            if action not in TOOLS:
                step_outputs.append(f"‚ùå Error: Tool '{action}' not found.")
                continue

            print(f"üîß Executing: {action}")
            result = execute_tool_dynamic(action, args)
            print(f"üìÑ Result: {result[:200]}..." if len(result) > 200 else f"üìÑ Result: {result}")
            step_outputs.append(f"Tool Output ({action}): {result}")

            # Strict Atomicity: Execute one tool, then think again
            break

        if task_finished:
            print(f"\n‚úÖ APOLLO RESPONSE: {result}")
            return result

        history.append({"role": "assistant", "content": content})
        history.append({"role": "user", "content": "\n".join(step_outputs)})

    print("‚ùå FAILED: Max steps reached.")

if __name__ == "__main__":
    # Example usage for testing
    if len(sys.argv) > 1:
        run_apollo_task(sys.argv[1])
    else:
        run_apollo_task("How many users are registered?")
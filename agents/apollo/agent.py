import json
import logging
import re
import os
import sys
import ast
import time
from typing import Dict, Any, List
import core.network_fix

# ‚úÖ Core Modules (Lightweight Imports)
from core.llm_client import query_qwen
from core.config import settings

# Logging Setup
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - [Apollo] %(message)s')
logger = logging.getLogger("ApolloAgent")
os.environ["ANONYMIZED_TELEMETRY"] = "False"

# ‚úÖ Reuse Parser Logic (‡∏î‡∏∂‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô Global Helper)
def robust_json_parser(text: str) -> Dict[str, Any]:
    """ ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏Å‡∏∞ JSON ‡∏´‡∏£‡∏∑‡∏≠ Python Dict ‡∏à‡∏≤‡∏Å Text ‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ """
    # 1. ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Parser ‡∏ï‡∏±‡∏ß‡πÄ‡∏Å‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì _extract_all_jsons
    extracted = _extract_all_jsons(text)
    if extracted:
        return extracted[0]  # ‡πÄ‡∏≠‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠

    # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏•‡∏≠‡∏á‡∏ó‡πà‡∏≤‡πÑ‡∏°‡πâ‡∏ï‡∏≤‡∏¢ clean string
    try:
        clean = text.strip()
        if clean.startswith("```json"): clean = clean[7:]
        if clean.startswith("```"): clean = clean[3:]
        if clean.endswith("```"): clean = clean[:-3]
        return json.loads(clean.strip())
    except:
        return {}

# ==============================================================================
# üõ†Ô∏è APOLLO SPECIFIC TOOLS
# ==============================================================================

# üü¢ Global Cache ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DB Connection (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Connect ‡∏ö‡πà‡∏≠‡∏¢)
_CACHED_DB = None

def get_db_connection():
    global _CACHED_DB
    if _CACHED_DB is None:
        from langchain_community.utilities import SQLDatabase
        # include_tables=['users', 'tickets'] # üí° ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ñ‡πâ‡∏≤ DB ‡πÉ‡∏´‡∏ç‡πà
        _CACHED_DB = SQLDatabase.from_uri(
            settings.DATABASE_URI,
            sample_rows_in_table_info=0,
            include_tables=['jira_knowledge'] # <--- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
        )
    return _CACHED_DB


def sync_recent_tickets(hours: int = 24) -> str:
    """
    Automatically syncs tickets that were updated within the last N hours.
    Useful for keeping the knowledge base fresh.
    """
    # üü¢ [LAZY LOAD]
    from core.tools.jira_ops import get_recently_updated_issues
    logger.info(f"üîÑ Apollo starting batch sync for the last {hours} hours...")

    # 1. ‡πÑ‡∏õ‡∏î‡∏∂‡∏á Keys ‡∏°‡∏≤
    issue_keys = get_recently_updated_issues(hours)

    if not issue_keys:
        return f"‚úÖ No tickets were updated in the last {hours} hours. Everything is up to date!"

    # 2. ‡∏ß‡∏ô‡∏•‡∏π‡∏õ Sync ‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß (‡πÉ‡∏ä‡πâ function sync_ticket ‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà)
    sync_results = []
    for key in issue_keys:
        try:
            status = sync_ticket_to_knowledge_base(key)
            sync_results.append(f"- {key}: {status}")
        except Exception as e:
            logger.error(f"‚ùå Failed to sync {key}: {e}")
            sync_results.append(f"- {key}: FAILED (Error: {str(e)})")

    return f"üöÄ Sync Complete for the last {hours}h:\n" + "\n".join(sync_results)


def ask_database_analyst(question: str) -> str:
    """
    Expert on Data & Statistics.
    Queries the live application database using SQL.
    (Manual Execution with Advanced Prompting)
    """
    from langchain_community.utilities import SQLDatabase
    from core.llm_client import query_qwen
    import re

    logger.info(f"üìä Analyst querying: {question}")

    try:
        # 1. Connect DB
        # ‡πÉ‡∏™‡πà include_tables=['...'] ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î Schema
        app_db = get_db_connection()

        # 2. ‡∏î‡∏∂‡∏á Schema
        database_schema = app_db.get_table_info()

        # 3. üî• Setup Prompt (‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Ç‡∏≠‡∏°‡∏≤‡πÄ‡∏õ‡πä‡∏∞‡πÜ)
        forced_prompt = (
            f"Role: You are an Intelligent SQL Data Analyst.\n"
            f"Goal: Answer the user's question accurately using the PostgreSQL database.\n\n"
            f"‚ö° **LIVE DATABASE SCHEMA**:\n"
            f"{database_schema}\n\n"
            f"‚ö†Ô∏è **CRITICAL INSTRUCTIONS**:\n"
            f"1. **Output**: You MUST output the SQL query in the 'Action Input' field.\n"
            f"2. **Format**: You MUST use the standard ReAct format:\n"
            f"   Thought: [Your reasoning]\n"
            f"   Action: sql_db_query\n"
            f"   Action Input: [SQL Query ONLY]\n"
            f"3. **No Chatting**: Do not start with 'Here is the query'. Start directly with 'Thought:'.\n\n"
            f"4. **NO MARKDOWN**: Do NOT wrap the SQL in ```sql ... ``` or ` ... `. \n"
            f"   - ‚ùå WRONG: ```sql SELECT * FROM table ``` \n"
            f"   - ‚úÖ RIGHT: SELECT * FROM table \n\n"
            f"üß† THINKING PROTOCOL (Must follow):\n"
            f"1. **Analyze Intent**: Does the user want to Count? List? Sum? or Check details?\n"
            f"2. **Identify Table**: Look for the most relevant table based on keywords.\n"
            f"3. **Inspect Data (Crucial)**: Run `SELECT DISTINCT column FROM table LIMIT 10` first if filtering by text.\n"
            f"4. **Execute Final Query**: Generate the specific SQL.\n\n"
            f"Question: {question}\n\n"
            f"Let's think step by step.\n"
        )

        messages = [
            {"role": "user", "content": forced_prompt}
        ]

        # 4. ‡πÉ‡∏´‡πâ AI ‡∏Ñ‡∏¥‡∏î (‡πÉ‡∏ä‡πâ query_qwen ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)
        logger.info("ü§ñ Generating SQL Plan...")
        raw_response = query_qwen(messages, temperature=0.1)

        # 5. üîç Parser: ‡πÅ‡∏Å‡∏∞ SQL ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å ReAct Format
        # ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Logic ‡πÅ‡∏Å‡∏∞‡πÄ‡∏≠‡∏á‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ LangChain Agent Executor ‡πÅ‡∏•‡πâ‡∏ß
        sql_query = ""

        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î Action Input:
        match = re.search(r"Action Input:\s*(.*)", raw_response, re.DOTALL | re.IGNORECASE)
        if match:
            sql_query = match.group(1).strip()
        else:
            # Fallback: ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤ Action Input ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ SELECT
            logger.warning("‚ö†Ô∏è ReAct format mismatch, trying to find raw SQL...")
            sql_matches = re.findall(r"(SELECT\s.*)", raw_response, re.DOTALL | re.IGNORECASE)
            if sql_matches:
                sql_query = sql_matches[-1]  # ‡πÄ‡∏≠‡∏≤‡∏ï‡∏±‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
            else:
                return f"‚ùå Could not extract SQL from response:\n{raw_response}"

        # 6. Cleaning (‡πÄ‡∏ú‡∏∑‡πà‡∏≠ AI ‡∏î‡∏∑‡πâ‡∏≠‡πÉ‡∏™‡πà Markdown ‡∏°‡∏≤)
        if "```" in sql_query:
            sql_query = sql_query.replace("```sql", "").replace("```", "").strip()

        # ‡∏•‡∏ö comment ‡∏ó‡πâ‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        sql_query = sql_query.split(";")[0]

        logger.info(f"üöÄ Executing SQL: {sql_query}")

        # 7. ‡∏£‡∏±‡∏ô SQL ‡∏à‡∏£‡∏¥‡∏á
        try:
            result_str = app_db.run(sql_query)

            # ‡∏à‡∏±‡∏î Format ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°
            final_output = (
                f"üìä **Database Analysis Result**:\n"
                f"--------------------------------\n"
                f"üß† **Thought**: {raw_response.split('Action')[0].replace('Thought:', '').strip()}\n"
                f"üíª **Query**: `{sql_query}`\n"
                f"‚úÖ **Answer**: {result_str}"
            )
            return final_output

        except Exception as sql_err:
            return f"‚ùå SQL Execution Error: {sql_err}\nQuery was: {sql_query}"

    except Exception as e:
        logger.error(f"‚ùå Critical Analyst Error: {e}")
        return f"‚ùå System Error: {e}"


def ask_guru(question: str) -> str:
    """
    Expert on Business Logic & Jira Tickets.
    Uses Vector Database and Internal Knowledge SQL.
    """
    # üü¢ [LAZY LOAD]
    from knowledge_base.vector_store import search_vector_db
    from core.tools.knowledge_ops import get_knowledge_from_sql

    logger.info(f"üîé Guru received: {question}")

    # üéØ Layer 1: The Sniper (Exact Match via Regex)
    ticket_pattern = r"([A-Z]+-\d+)"
    matches = re.findall(ticket_pattern, question)

    if matches:
        logger.info(f"üéØ Direct Lookup IDs: {matches}")
        results = []
        for ticket_key in matches:
            data = get_knowledge_from_sql(ticket_key)
            if data:
                results.append(f"üìÑ Ticket {ticket_key}:\n{data}")

        if results:
            return "\n---\n".join(results)

    # üìö Layer 2: The Librarian (Vector Search)
    logger.info("üß† Fallback to Semantic Search...")
    try:
        results = search_vector_db(question, k=4)
        if not results or "no relevant info" in results.lower():
            return "‚ùå No info found in knowledge base."
        return f"üìö Relevant Docs found:\n{results}"
    except Exception as e:
        return f"‚ùå Search Error: {e}"


def sync_ticket_to_knowledge_base(issue_key: str) -> str:
    """
    Orchestrate the sync process: Read Jira -> Extract Info using LLM -> Save to Vector DB
    """
    # üü¢ [LAZY LOAD]
    from core.tools.jira_ops import get_jira_issue
    from core.tools.knowledge_ops import save_knowledge

    logger.info(f"üîÑ Syncing Ticket: {issue_key}")

    # 1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (One Shot)
    ticket_data = get_jira_issue(issue_key)

    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ Error ‡πÑ‡∏´‡∏°
    if not ticket_data.get("success"):
        return f"‚ùå Sync Failed: {ticket_data.get('error')}"

    # ‚úÖ Extract Variables
    raw_content = ticket_data["ai_content"]
    real_status = ticket_data["status"]
    real_type = ticket_data["issue_type"]
    real_summary = ticket_data["summary"]
    real_parent_key = ticket_data.get("parent_key")
    real_issue_links = ticket_data.get("issue_links")

    # 2. ‡πÉ‡∏ä‡πâ‡∏™‡∏°‡∏≠‡∏á (Qwen) ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    extraction_prompt = [
        {"role": "system", "content": """
        You are a Data Extractor parsing Jira ticket content into structured JSON.
        Extract the following fields strictly:
        - summary: The title of the ticket.
        - status: The current status (e.g., To Do, Done).
        - business_logic: The core rules and requirements.
        - technical_spec: API endpoints, database changes, or technical constraints.
        - test_scenarios: Acceptance criteria or test cases mentioned.
        - issue_type: (Story, Bug, Task).
        
        STRICT RULES:
        1. Use double quotes (") for keys and string values.
        2. Escape inner quotes properly (e.g. "behavior": "Returns \\"Error\\" message").
        3. Do NOT use single quotes (') for JSON strings.
        4. Output JSON ONLY. No markdown, no explanations.
        """},
        {"role": "user", "content": f"Parse this ticket content:\n\n{raw_content}"}
    ]

    try:
        llm_response = query_qwen(extraction_prompt)

        # Handle Response Type
        if isinstance(llm_response, dict):
            content_text = llm_response.get('content', '') or llm_response.get('message', {}).get('content', '')
        else:
            content_text = str(llm_response)

        # üõ°Ô∏è Safety Clean
        content_text = content_text.strip()
        if content_text.startswith("```json"): content_text = content_text[7:]
        if content_text.endswith("```"): content_text = content_text[:-3]
        content_text = content_text.strip()

        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Dict
        data = robust_json_parser(content_text)

        # Helper Serialize
        def safe_serialize(obj):
            if isinstance(obj, (dict, list)):
                return json.dumps(obj, ensure_ascii=False, indent=2)
            return str(obj) if obj else "-"

        # 3. Save ‡∏•‡∏á DB
        result = save_knowledge(
            issue_key=issue_key,
            summary=real_summary,
            status=real_status,
            business_logic=safe_serialize(data.get("business_logic")),
            technical_spec=safe_serialize(data.get("technical_spec")),
            test_scenarios=safe_serialize(data.get("test_scenarios")),
            issue_type=real_type,
            parent_key=real_parent_key,  # ‚úÖ New Field
            issue_links=real_issue_links  # ‚úÖ New Field
        )

        return f"‚úÖ Synced {issue_key} successfully!\nDetails: {result}"

    except json.JSONDecodeError as je:
        logger.error(f"‚ùå JSON Error: {je} \nRaw Text: {content_text}")
        save_knowledge(
            issue_key=issue_key,
            summary=f"[AI Error] {real_summary}",
            status=real_status,
            business_logic=f"‚ö†Ô∏è AI Parsing Failed. Raw Content:\n{raw_content[:2000]}",
            technical_spec="-",
            test_scenarios="-",
            issue_type=real_type,
            parent_key=real_parent_key,
            issue_links=real_issue_links
        )
        return f"‚ö†Ô∏è Synced {issue_key} (Metadata OK, but AI Analysis failed). Saved raw content."

    except Exception as e:
        logger.error(f"‚ùå General Error: {e}")
        return f"‚ùå Sync Failed: {e}"


# ==============================================================================
# üß© TOOLS REGISTRY
# ==============================================================================
TOOLS = {
    "ask_guru": ask_guru,
    "ask_database_analyst": ask_database_analyst,
    "sync_ticket": sync_ticket_to_knowledge_base,
    "sync_recent_tickets": sync_recent_tickets # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ
}


def execute_tool_dynamic(tool_name: str, args: Dict[str, Any]) -> str:
    if tool_name not in TOOLS: return f"Error: Unknown tool '{tool_name}'"
    try:
        func = TOOLS[tool_name]
        return str(func(**args))
    except Exception as e:
        return f"Error executing {tool_name}: {e}"


# ==============================================================================
# üß† SYSTEM PROMPT
# ==============================================================================
SYSTEM_PROMPT = """
You are "Apollo", the Knowledge Guru & Data Analyst of Olympus.

*** üß† DECISION TREE (Follow Strictly) ***

1. **CASE: User asks for DEFINITION / LOGIC / CONTENT** üìñ
   - Examples: "What is SCRUM-26?", "Explain the login flow".
   - ‚úÖ ACTION: Use `ask_guru(question)`.

2. **CASE: User asks for NUMBERS / LISTS / AGGREGATION** üìä
   - Examples: "How many tickets?", "Count users".
   - ‚úÖ ACTION: Use `ask_database_analyst(question)`.

3. **CASE: User asks to MEMORIZE / SYNC** üì•
   - Examples: "Sync SCRUM-27", "Read this ticket".
   - ‚úÖ ACTION: Use `sync_ticket(issue_key)`.

4. **CASE: User wants to UPDATE/REFRESH KNOWLEDGE by TIME** üîÑ
   - Examples: "Update tickets from today", "Sync last 5 hours", "Refresh knowledge base".
   - ‚úÖ ACTION: Use `sync_recent_tickets(hours)`.

*** ‚ö†Ô∏è RULES ***
- Do NOT guess. If you need stats, ask the analyst.
- If the user doesn't specify hours for "sync today" or "sync recent", assume hours=24.
- If you need content, ask the guru.
- Output JSON format only.

*** ‚ö†Ô∏è CRITICAL RULES ***
1. **ATOMICITY**: One tool per turn. Wait for result.
2. **JSON FORMAT**: No comments. Strict JSON.

*** üõ†Ô∏è TOOLS AVAILABLE ***
- sync_ticket(issue_key): Syncs one specific Jira ticket.
- sync_recent_tickets(hours): Scans and syncs all tickets updated within the last N hours.
- ask_guru(question): Search internal knowledge/vector DB for logic and business rules.
- ask_database_analyst(question): Executes SQL queries for statistics and counts.
- task_complete(summary): Final answer after all actions are done.

RESPONSE FORMAT (JSON ONLY):
{ "action": "tool_name", "args": { ... } }
"""


# ==============================================================================
# üß© HELPER: PARSERS (Standardized)
# ==============================================================================
def extract_code_block(text: str) -> str:
    """Extract content from Markdown code blocks."""
    matches = re.findall(r"```\w*\n(.*?)```", text, re.DOTALL)
    if not matches: return ""
    for content in reversed(matches):
        cleaned = content.strip()
        if not ('"action":' in cleaned and '"args":' in cleaned):
            return cleaned
    return ""


def _extract_all_jsons(text: str) -> List[Dict[str, Any]]:
    """ robust JSON extractor handling multiple blocks and python dict strings """
    results = []
    decoder = json.JSONDecoder()
    pos = 0
    while pos < len(text):
        try:
            search = re.search(r"\{", text[pos:])
            if not search: break
            start_index = pos + search.start()
            obj, end_index = decoder.raw_decode(text, idx=start_index)
            if isinstance(obj, dict) and "action" in obj:
                results.append(obj)
            pos = end_index
        except:
            pos += 1

    # Fallback for Python dict strings
    if not results:
        try:
            matches = re.findall(r"(\{.*?\})", text, re.DOTALL)
            for match in matches:
                try:
                    clean = match.replace("true", "True").replace("false", "False").replace("null", "None")
                    obj = ast.literal_eval(clean)
                    if isinstance(obj, dict) and "action" in obj: results.append(obj)
                except:
                    continue
        except:
            pass

    return results


# ==============================================================================
# üöÄ MAIN LOOP
# ==============================================================================
def run_apollo_task(task: str, max_steps: int = 15):
    if settings.CURRENT_AGENT_NAME != "Apollo":
        settings.CURRENT_AGENT_NAME = "Apollo"

    print(f"üèõÔ∏è Launching Apollo (Knowledge Guru)...")
    print(f"üìã Question/Task: {task}")

    history = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": task}
    ]

    for step in range(max_steps):
        print(f"\nüîÑ Thinking (Step {step + 1})...")
        try:
            response = query_qwen(history)
            if isinstance(response, dict):
                content = response.get('message', {}).get('content', '') or response.get('content', '')
            else:
                content = str(response)
        except Exception as e:
            print(f"‚ùå Error querying LLM: {e}")
            return

        print(f"ü§ñ Apollo: {content[:100]}...")
        tool_calls = _extract_all_jsons(content)

        if not tool_calls:
            if "task_complete" not in content and "action" not in content:
                print(f"‚ÑπÔ∏è Apollo Answer: {content}")
                history.append({"role": "assistant", "content": content})
            else:
                history.append({"role": "assistant", "content": content})
            continue

        step_outputs = []
        task_finished = False

        for tool_call in tool_calls:
            action = tool_call.get("action")
            args = tool_call.get("args", {})

            if action == "task_complete":
                task_finished = True
                result = args.get("summary", "Done")
                step_outputs.append(f"Task Completed: {result}")
                break

            if action not in TOOLS:
                step_outputs.append(f"‚ùå Error: Tool '{action}' not found.")
                continue

            print(f"üîß Executing: {action}")
            result = execute_tool_dynamic(action, args)
            print(f"üìÑ Result: {result[:200]}..." if len(result) > 200 else f"üìÑ Result: {result}")
            step_outputs.append(f"Tool Output ({action}): {result}")
            break

        if task_finished:
            print(f"\n‚úÖ APOLLO RESPONSE: {result}")
            return result

        history.append({"role": "assistant", "content": content})
        history.append({"role": "user", "content": "\n".join(step_outputs)})

    print("‚ùå FAILED: Max steps reached.")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        run_apollo_task(sys.argv[1])
    else:
        run_apollo_task("How many users are registered?")
import os
import logging
from typing import List, Dict

# ‚úÖ ‡πÉ‡∏ä‡πâ Library ‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ñ‡∏ô‡∏±‡∏î (LangChain)
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_core.documents import Document

# Setup Path
CURRENT_FILE_PATH = os.path.abspath(__file__)
BASE_DIR = os.path.dirname(os.path.dirname(CURRENT_FILE_PATH)) # Olympus-Agents Root
PERSIST_DIRECTORY = os.path.join(BASE_DIR, "chroma_db")

# Setup Embeddings (‡πÉ‡∏ä‡πâ Ollama ‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏¥‡∏°)
embeddings = OllamaEmbeddings(
    model="nomic-embed-text",  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ `ollama pull nomic-embed-text` ‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö
    base_url="http://localhost:11434"
)

# Load Vector DB
vector_db = Chroma(
    collection_name="jira_knowledge",
    embedding_function=embeddings,
    persist_directory=PERSIST_DIRECTORY
)

def add_ticket_to_vector(issue_key: str, summary: str, content: str):
    """
    Save ticket data to Vector DB.
    Content ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ Business Logic + Tech Spec ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏£‡πà‡∏≤‡∏á‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
    """
    logging.info(f"üß† VECTOR: Embedding ticket {issue_key}...")

    full_text = f"""
    Ticket: {issue_key}
    Summary: {summary}
    Knowledge: {content}
    """

    doc = Document(
        page_content=full_text,
        metadata={"issue_key": issue_key, "source": "jira"}
    )

    # ‚úÖ ‡∏•‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô)
    try:
        # ‡∏î‡∏∂‡∏á ID ‡πÄ‡∏Å‡πà‡∏≤‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
        existing_docs = vector_db.get(where={"issue_key": issue_key})
        if existing_docs and existing_docs['ids']:
            vector_db.delete(ids=existing_docs['ids'])
            logging.info(f"‚ôªÔ∏è Updated existing vector for {issue_key}")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Vector delete warning: {e}")

    # ‡πÄ‡∏û‡∏¥‡πà‡∏° Vector ‡πÉ‡∏´‡∏°‡πà
    vector_db.add_documents([doc])
    logging.info(f"‚úÖ VECTOR: Saved {issue_key} successfully.")

def search_vector_db(query: str, k: int = 4):
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (Semantic Search)"""
    logging.info(f"üß† Semantic Searching for: '{query}'")

    results = vector_db.similarity_search_with_score(query, k=k)

    if not results:
        return "‚ùå No relevant info found in Vector DB."

    parsed_results = []
    for doc, score in results:
        parsed_results.append(f"""
        --- MATCH (Score: {score:.2f}) ---
        Key: {doc.metadata.get('issue_key')}
        Content: {doc.page_content}
        -----------------------------------
        """)

    return "\n".join(parsed_results)
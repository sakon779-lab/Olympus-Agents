import os
import logging
from typing import List, Dict

# ‚úÖ ‡πÉ‡∏ä‡πâ Library ‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ñ‡∏ô‡∏±‡∏î (LangChain)
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_core.documents import Document

# Setup Path
CURRENT_FILE_PATH = os.path.abspath(__file__)
BASE_DIR = os.path.dirname(os.path.dirname(CURRENT_FILE_PATH))  # Olympus-Agents Root
PERSIST_DIRECTORY = os.path.join(BASE_DIR, "chroma_db")

# ---------------------------------------------------------
# ‚ö° LAZY LOADING SETUP (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Time Out)
# ---------------------------------------------------------
# ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ Global ‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô None ‡∏Å‡πà‡∏≠‡∏ô (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÇ‡∏´‡∏•‡∏î)
_VECTOR_DB = None
_EMBEDDINGS = None


def get_vector_db():
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞ Init DB ‡∏Å‡πá‡∏ï‡πà‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    ‡∏ó‡∏≥‡πÉ‡∏´‡πâ Server Start ‡πÄ‡∏£‡πá‡∏ß‡∏õ‡∏£‡∏π‡πä‡∏î‡∏õ‡∏£‡πä‡∏≤‡∏î!
    """
    global _VECTOR_DB, _EMBEDDINGS

    if _VECTOR_DB is None:
        logging.info("‚è≥ Initializing Vector DB (Lazy Load)...")

        # 1. Init Embeddings
        _EMBEDDINGS = OllamaEmbeddings(
            model="nomic-embed-text",
            base_url="http://localhost:11434"
        )

        # 2. Init Chroma
        _VECTOR_DB = Chroma(
            collection_name="jira_knowledge",
            embedding_function=_EMBEDDINGS,
            persist_directory=PERSIST_DIRECTORY
        )
        logging.info("‚úÖ Vector DB Ready!")

    return _VECTOR_DB


# ---------------------------------------------------------
# FUNCTION CALLS (‡πÅ‡∏Å‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ú‡πà‡∏≤‡∏ô get_vector_db())
# ---------------------------------------------------------

def add_ticket_to_vector(issue_key: str, summary: str, content: str):
    """
    Save ticket data to Vector DB.
    """
    # ‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ú‡πà‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏ó‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡∏£‡∏á‡πÜ
    db = get_vector_db()

    logging.info(f"üß† VECTOR: Embedding ticket {issue_key}...")

    full_text = f"""
    Ticket: {issue_key}
    Summary: {summary}
    Knowledge: {content}
    """

    doc = Document(
        page_content=full_text,
        metadata={"issue_key": issue_key, "source": "jira"}
    )

    try:
        # ‡∏î‡∏∂‡∏á ID ‡πÄ‡∏Å‡πà‡∏≤‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
        existing_docs = db.get(where={"issue_key": issue_key})
        if existing_docs and existing_docs['ids']:
            db.delete(ids=existing_docs['ids'])
            logging.info(f"‚ôªÔ∏è Updated existing vector for {issue_key}")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Vector delete warning: {e}")

    # ‡πÄ‡∏û‡∏¥‡πà‡∏° Vector ‡πÉ‡∏´‡∏°‡πà
    db.add_documents([doc])
    logging.info(f"‚úÖ VECTOR: Saved {issue_key} successfully.")


def search_vector_db(query: str, k: int = 4):
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (Semantic Search)"""
    # ‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ú‡πà‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏ó‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡∏£‡∏á‡πÜ
    db = get_vector_db()

    logging.info(f"üß† Semantic Searching for: '{query}'")

    results = db.similarity_search_with_score(query, k=k)

    if not results:
        return "‚ùå No relevant info found in Vector DB."

    parsed_results = []
    for doc, score in results:
        parsed_results.append(f"""
        --- MATCH (Score: {score:.2f}) ---
        Key: {doc.metadata.get('issue_key')}
        Content: {doc.page_content}
        -----------------------------------
        """)

    return "\n".join(parsed_results)